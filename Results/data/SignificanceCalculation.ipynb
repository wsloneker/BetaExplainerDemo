{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd4ff9c-d3d3-4b86-bae7-382fed8dd4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, ttest_ind, wilcoxon, f_oneway, kruskal, permutation_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01bebeab-98d1-476d-af7e-a54462b5ccaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def statistic(x, y):\n",
    "    return np.mean(x, axis=0) - np.mean(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8916fb7e-62d5-48dc-8a5a-bae3613a2dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492f3ac3-3fe2-4bd1-a4ab-ab14ca3a4001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whitn\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "df_cora2 = pd.read_csv('Cora/CoraBetaRandomSeedConsistancy.csv')\n",
    "df_cora4 = pd.read_csv('Cora/CoraGNNRandomSeedConsistancy.csv')\n",
    "frames = [df_cora2, df_cora4]\n",
    "df_sp_fid = pd.concat(frames)\n",
    "df_sp_fid = df_sp_fid.rename(columns={'Phen Pos Fidelity':'Positive Phenomenon Fidelity',\n",
    "                                        'Phen Neg Fidelity':'Negative Phenomenon Fidelity',\n",
    "                                        'Model Pos Fidelity':'Positive Model Fidelity',\n",
    "                                        'Model Neg Fidelity':'Negative Model Fidelity',\n",
    "                                        'Exp Size Percent':'Fraction of Edges in Explanation'\n",
    "                                       })\n",
    "wp = 0.5\n",
    "wn = 0.5\n",
    "df_sp_fid['Num'] = (wp + wn) * df_sp_fid['Positive Phenomenon Fidelity'] * (1 - df_sp_fid['Negative Phenomenon Fidelity'])\n",
    "df_sp_fid['Denom'] = wp * (1 - df_sp_fid['Negative Phenomenon Fidelity']) + wn * df_sp_fid['Positive Phenomenon Fidelity']\n",
    "df_sp_fid['Phenomenon Characterization Score'] = df_sp_fid['Num'] / df_sp_fid['Denom']\n",
    "df_sp_fid['Num'] = (wp + wn) * df_sp_fid['Positive Model Fidelity'] * (1 - df_sp_fid['Negative Model Fidelity'])\n",
    "df_sp_fid['Denom'] = wp * (1 - df_sp_fid['Negative Model Fidelity']) + wn * df_sp_fid['Positive Model Fidelity']\n",
    "df_sp_fid['Model Characterization Score'] = df_sp_fid['Num'] / df_sp_fid['Denom']\n",
    "cat = ['Phenomenon Characterization Score', 'Model Characterization Score', \n",
    "       'Fraction of Edges in Explanation', 'Unfaithfulness']\n",
    "gnn = df_sp_fid[df_sp_fid['Explainer'] == 'GNN']\n",
    "beta = df_sp_fid[df_sp_fid['Explainer'] == 'Beta']\n",
    "for c in cat:\n",
    "    x = list(gnn[c])\n",
    "    y = list(beta[c])\n",
    "    mwu = mannwhitneyu(x, y)\n",
    "    tt = ttest_ind(x, y)\n",
    "    #w = wilcoxon(x, y)\n",
    "    #k = kruskal(x, y)\n",
    "    pt = permutation_test((x, y), statistic)\n",
    "    results.append(['Cora', c, mwu.pvalue, tt.pvalue, pt.pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90b9799-1f7a-4dce-8bc1-85e8f2088999",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whitn\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "df_cs2 = pd.read_csv('CiteSeer/CiteSeerBetaRandomSeedConsistancy.csv')\n",
    "df_cs4 = pd.read_csv('CiteSeer/CiteSeerGNNRandomSeedConsistancy.csv')\n",
    "frames = [df_cs2, df_cs4]\n",
    "df_sp_fid = pd.concat(frames)\n",
    "df_sp_fid = df_sp_fid.rename(columns={'Phen Pos Fidelity':'Positive Phenomenon Fidelity',\n",
    "                                        'Phen Neg Fidelity':'Negative Phenomenon Fidelity',\n",
    "                                        'Model Pos Fidelity':'Positive Model Fidelity',\n",
    "                                        'Model Neg Fidelity':'Negative Model Fidelity',\n",
    "                                        'Exp Size Percent':'Fraction of Edges in Explanation'\n",
    "                                       })\n",
    "wp = 0.5\n",
    "wn = 0.5\n",
    "df_sp_fid['Num'] = (wp + wn) * df_sp_fid['Positive Phenomenon Fidelity'] * (1 - df_sp_fid['Negative Phenomenon Fidelity'])\n",
    "df_sp_fid['Denom'] = wp * (1 - df_sp_fid['Negative Phenomenon Fidelity']) + wn * df_sp_fid['Positive Phenomenon Fidelity']\n",
    "df_sp_fid['Phenomenon Characterization Score'] = df_sp_fid['Num'] / df_sp_fid['Denom']\n",
    "df_sp_fid['Num'] = (wp + wn) * df_sp_fid['Positive Model Fidelity'] * (1 - df_sp_fid['Negative Model Fidelity'])\n",
    "df_sp_fid['Denom'] = wp * (1 - df_sp_fid['Negative Model Fidelity']) + wn * df_sp_fid['Positive Model Fidelity']\n",
    "df_sp_fid['Model Characterization Score'] = df_sp_fid['Num'] / df_sp_fid['Denom']\n",
    "cat = ['Phenomenon Characterization Score', 'Model Characterization Score', \n",
    "       'Fraction of Edges in Explanation', 'Unfaithfulness']\n",
    "gnn = df_sp_fid[df_sp_fid['Explainer'] == 'GNN']\n",
    "beta = df_sp_fid[df_sp_fid['Explainer'] == 'Beta']\n",
    "for c in cat:\n",
    "    x = list(gnn[c])\n",
    "    y = list(beta[c])\n",
    "    mwu = mannwhitneyu(x, y)\n",
    "    tt = ttest_ind(x, y)\n",
    "    #w = wilcoxon(x, y)\n",
    "    #k = kruskal(x, y)\n",
    "    pt = permutation_test((x, y), statistic)\n",
    "    results.append(['CiteSeer', c, mwu.pvalue, tt.pvalue, pt.pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b42b1a2d-dba7-44c4-8b26-1213da016e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whitn\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "df_s25_2 = pd.read_csv('SERGIO/SeedConsistancySERGIO25beta.csv')\n",
    "df_s25_4 = pd.read_csv('SERGIO/SeedConsistancySERGIO25gnn.csv')\n",
    "frames = [df_s25_2, df_s25_4]\n",
    "df_sergio = pd.concat(frames)\n",
    "df_sergio['Explainer'] = df_sergio['Explainer'].apply({'gnn':'GNN', 'beta':'Beta','GNN':'GNN','Beta':'Beta'}.get)\n",
    "df_sergio['F1 Score'] = (2 * df_sergio['Torch Precision'] * df_sergio['Torch Recall']) / (df_sergio['Torch Precision'] + df_sergio['Torch Recall'])\n",
    "df_sergio['Full F1 Score'] = (2 * df_sergio['Precision'] * df_sergio['Recall']) / (df_sergio['Precision'] + df_sergio['Recall'])\n",
    "df_sergio = df_sergio.rename(columns={'Accuracy': 'Full Accuracy', 'Precision': 'Full Precision', \n",
    "                                      'Recall': 'Full Recall'})\n",
    "df_sergio = df_sergio.rename(columns={'Torch Accuracy':'Accuracy','Torch Recall':\n",
    "                                      'Recall','Torch Precision':'Precision', 'Faithfulness':'Unfaithfulness'})\n",
    "df_sergio = df_sergio.fillna(0)\n",
    "cat = ['Full Accuracy', 'Full F1 Score', 'Accuracy', 'F1 Score',\n",
    "       'Unfaithfulness']\n",
    "gnn = df_sergio[df_sergio['Explainer'] == 'GNN']\n",
    "beta = df_sergio[df_sergio['Explainer'] == 'Beta']\n",
    "for c in cat:\n",
    "    x = list(gnn[c])\n",
    "    y = list(beta[c])\n",
    "    mwu = mannwhitneyu(x, y)\n",
    "    tt = ttest_ind(x, y)\n",
    "    #w = wilcoxon(x, y)\n",
    "    #k = kruskal(x, y)\n",
    "    pt = permutation_test((x, y), statistic)\n",
    "    results.append(['SERGIO 25', c, mwu.pvalue, tt.pvalue, pt.pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77a7fdf-6b61-4125-9b46-f5b64b85e264",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\whitn\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "df_s25_2 = pd.read_csv('SERGIO/SeedConsistancySERGIO50beta.csv')\n",
    "df_s25_4 = pd.read_csv('SERGIO/SeedConsistancySERGIO50gnn.csv')\n",
    "frames = [df_s25_2, df_s25_4]\n",
    "df_sergio = pd.concat(frames)\n",
    "df_sergio['Explainer'] = df_sergio['Explainer'].apply({'gnn':'GNN', 'beta':'Beta','GNN':'GNN','Beta':'Beta'}.get)\n",
    "df_sergio['F1 Score'] = (2 * df_sergio['Torch Precision'] * df_sergio['Torch Recall']) / (df_sergio['Torch Precision'] + df_sergio['Torch Recall'])\n",
    "df_sergio['Full F1 Score'] = (2 * df_sergio['Precision'] * df_sergio['Recall']) / (df_sergio['Precision'] + df_sergio['Recall'])\n",
    "df_sergio = df_sergio.rename(columns={'Accuracy': 'Full Accuracy', 'Precision': 'Full Precision', \n",
    "                                      'Recall': 'Full Recall'})\n",
    "df_sergio = df_sergio.rename(columns={'Torch Accuracy':'Accuracy','Torch Recall':\n",
    "                                      'Recall','Torch Precision':'Precision', 'Faithfulness':'Unfaithfulness'})\n",
    "df_sergio = df_sergio.fillna(0)\n",
    "cat = ['Full Accuracy', 'Full F1 Score', 'Accuracy', 'F1 Score',\n",
    "       'Unfaithfulness']\n",
    "gnn = df_sergio[df_sergio['Explainer'] == 'GNN']\n",
    "beta = df_sergio[df_sergio['Explainer'] == 'Beta']\n",
    "for c in cat:\n",
    "    x = list(gnn[c])\n",
    "    y = list(beta[c])\n",
    "    mwu = mannwhitneyu(x, y)\n",
    "    tt = ttest_ind(x, y)\n",
    "    #w = wilcoxon(x, y)\n",
    "    #k = kruskal(x, y)\n",
    "    pt = permutation_test((x, y), statistic)\n",
    "    results.append(['SERGIO 50', c, mwu.pvalue, tt.pvalue, pt.pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "385c2b72-a517-4ada-b060-4e8af76c0d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_base2 = pd.read_csv('xAI/baseBetaExpxAISeedResults.csv')\n",
    "df_base4 = pd.read_csv('xAI/baseGNNExpxAISeedResults.csv')\n",
    "beta = df_base2\n",
    "gnn = df_base4\n",
    "gnn['F1 Score'] = (2 * gnn['Best Prec'] * gnn['Best Rec']) / (gnn['Best Prec'] + gnn['Best Rec'])\n",
    "beta['F1 Score'] = (2 * beta['Best Prec'] * beta['Best Rec']) / (beta['Best Prec'] + beta['Best Rec'])\n",
    "cat = ['Best Acc', 'Best Faith', 'F1 Score']\n",
    "for c in cat:\n",
    "    x = list(gnn[c])\n",
    "    y = list(beta[c])\n",
    "    mwu = mannwhitneyu(x, y)\n",
    "    tt = ttest_ind(x, y)\n",
    "    pt = permutation_test((x, y), statistic)\n",
    "    results.append(['SG-BASE', c, mwu.pvalue, tt.pvalue, pt.pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1680e583-fd9c-4146-9be8-a4503fbd4979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_base2 = pd.read_csv('xAI/heteroBetaExpxAISeedResults.csv')\n",
    "df_base4 = pd.read_csv('xAI/heteroGNNExpxAISeedResults.csv')\n",
    "beta = df_base2\n",
    "gnn = df_base4\n",
    "gnn['F1 Score'] = (2 * gnn['Best Prec'] * gnn['Best Rec']) / (gnn['Best Prec'] + gnn['Best Rec'])\n",
    "beta['F1 Score'] = (2 * beta['Best Prec'] * beta['Best Rec']) / (beta['Best Prec'] + beta['Best Rec'])\n",
    "cat = ['Best Acc', 'Best Faith', 'F1 Score']\n",
    "for c in cat:\n",
    "    x = list(gnn[c])\n",
    "    y = list(beta[c])\n",
    "    mwu = mannwhitneyu(x, y)\n",
    "    tt = ttest_ind(x, y)\n",
    "    pt = permutation_test((x, y), statistic)\n",
    "    results.append(['SG-HETEROPHILIC', c, mwu.pvalue, tt.pvalue, pt.pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d262798-e369-4684-ab3e-bdb0b9d49806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_base2 = pd.read_csv('xAI/lessinformBetaExpxAISeedResults.csv')\n",
    "df_base4 = pd.read_csv('xAI/lessinformGNNExpxAISeedResults.csv')\n",
    "beta = df_base2\n",
    "gnn = df_base4\n",
    "gnn['F1 Score'] = (2 * gnn['Best Prec'] * gnn['Best Rec']) / (gnn['Best Prec'] + gnn['Best Rec'])\n",
    "beta['F1 Score'] = (2 * beta['Best Prec'] * beta['Best Rec']) / (beta['Best Prec'] + beta['Best Rec'])\n",
    "cat = ['Best Acc', 'Best Faith', 'F1 Score']\n",
    "for c in cat:\n",
    "    x = list(gnn[c])\n",
    "    y = list(beta[c])\n",
    "    mwu = mannwhitneyu(x, y)\n",
    "    tt = ttest_ind(x, y)\n",
    "    pt = permutation_test((x, y), statistic)\n",
    "    results.append(['SG-LESSINFORM', c, mwu.pvalue, tt.pvalue, pt.pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29b1a7e3-9aae-4f70-a822-e720009cbe22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_base2 = pd.read_csv('xAI/moreinformBetaExpxAISeedResults.csv')\n",
    "df_base4 = pd.read_csv('xAI/moreinformGNNExpxAISeedResults.csv')\n",
    "beta = df_base2\n",
    "gnn = df_base4\n",
    "gnn['F1 Score'] = (2 * gnn['Best Prec'] * gnn['Best Rec']) / (gnn['Best Prec'] + gnn['Best Rec'])\n",
    "beta['F1 Score'] = (2 * beta['Best Prec'] * beta['Best Rec']) / (beta['Best Prec'] + beta['Best Rec'])\n",
    "cat = ['Best Acc', 'Best Faith', 'F1 Score']\n",
    "for c in cat:\n",
    "    x = list(gnn[c])\n",
    "    y = list(beta[c])\n",
    "    mwu = mannwhitneyu(x, y)\n",
    "    tt = ttest_ind(x, y)\n",
    "    pt = permutation_test((x, y), statistic)\n",
    "    results.append(['SG-MOREINFORM', c, mwu.pvalue, tt.pvalue, pt.pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a722bb30-729d-4f20-af3d-dc5eb0d5e982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_base2 = pd.read_csv('xAI/unfairBetaExpxAISeedResults.csv')\n",
    "df_base4 = pd.read_csv('xAI/unfairGNNExpxAISeedResults.csv')\n",
    "beta = df_base2\n",
    "gnn = df_base4\n",
    "gnn['F1 Score'] = (2 * gnn['Best Prec'] * gnn['Best Rec']) / (gnn['Best Prec'] + gnn['Best Rec'])\n",
    "beta['F1 Score'] = (2 * beta['Best Prec'] * beta['Best Rec']) / (beta['Best Prec'] + beta['Best Rec'])\n",
    "cat = ['Best Acc', 'Best Faith', 'F1 Score']\n",
    "for c in cat:\n",
    "    x = list(gnn[c])\n",
    "    y = list(beta[c])\n",
    "    mwu = mannwhitneyu(x, y)\n",
    "    tt = ttest_ind(x, y)\n",
    "    pt = permutation_test((x, y), statistic)\n",
    "    results.append(['SG-UNFAIR', c, mwu.pvalue, tt.pvalue, pt.pvalue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5ee245b-5c48-422d-bdbd-81a2525e8e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Category</th>\n",
       "      <th>MannWhitney-U</th>\n",
       "      <th>t-test</th>\n",
       "      <th>Permutation Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cora</td>\n",
       "      <td>Phenomenon Characterization Score</td>\n",
       "      <td>0.185877</td>\n",
       "      <td>6.778959e-02</td>\n",
       "      <td>0.0650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cora</td>\n",
       "      <td>Model Characterization Score</td>\n",
       "      <td>0.121225</td>\n",
       "      <td>6.743676e-02</td>\n",
       "      <td>0.0734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cora</td>\n",
       "      <td>Fraction of Edges in Explanation</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>6.471310e-11</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cora</td>\n",
       "      <td>Unfaithfulness</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CiteSeer</td>\n",
       "      <td>Phenomenon Characterization Score</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.579193e-01</td>\n",
       "      <td>0.7478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset                           Category  MannWhitney-U        t-test  \\\n",
       "0      Cora  Phenomenon Characterization Score       0.185877  6.778959e-02   \n",
       "1      Cora       Model Characterization Score       0.121225  6.743676e-02   \n",
       "2      Cora   Fraction of Edges in Explanation       0.000182  6.471310e-11   \n",
       "3      Cora                     Unfaithfulness       1.000000           NaN   \n",
       "4  CiteSeer  Phenomenon Characterization Score       1.000000  7.579193e-01   \n",
       "\n",
       "   Permutation Test  \n",
       "0            0.0650  \n",
       "1            0.0734  \n",
       "2            0.0002  \n",
       "3            1.0000  \n",
       "4            0.7478  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, columns=['Dataset', 'Category', 'MannWhitney-U', 't-test', 'Permutation Test'])\n",
    "df.to_csv('SignificanceResults.csv')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
